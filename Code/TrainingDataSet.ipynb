{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Twitter Sentiment Corpus \n",
    "\n",
    "In the following notebook, we are going to look at an example of sentimentally taged data set provided in [Twitter Sentiment Corpus](http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/) and clean in the same wasy as we processed out SB50 data set. \n",
    "\n",
    "I have cleaned the text by, removing the websites, all non-letter characters, all stopwords, '@', and 'rt' , which symbolizing retweets, from the text. \n",
    "\n",
    "I also have to test [Niek Sanders](http://www.sananalytics.com/lab/twitter-sentiment/) dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the needed libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "from pandas.tseries.resample import TimeGrouper\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from IPython.display import HTML\n",
    "import folium\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from scipy.misc import imread\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿ItemID  Sentiment SentimentSource  \\\n",
       "0        1          0    Sentiment140   \n",
       "1        2          0    Sentiment140   \n",
       "2        3          1    Sentiment140   \n",
       "3        4          0    Sentiment140   \n",
       "4        5          0    Sentiment140   \n",
       "\n",
       "                                       SentimentText  \n",
       "0                       is so sad for my APL frie...  \n",
       "1                     I missed the New Moon trail...  \n",
       "2                            omg its already 7:30 :O  \n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I'...  \n",
       "4           i think mi bf is cheating on me!!!   ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../Data/Sentiment Analysis Dataset.csv',error_bad_lines=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean (raw_text):\n",
    "\n",
    "#1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_text, 'html5lib').get_text() \n",
    "\n",
    "# 2. Remove non-letters and Remove website addresses       \n",
    "    letters_only = re.sub(r\"http\\S+\", \"\",review_text, flags=re.MULTILINE)\n",
    "    letters_only = re.sub(\"[^a-zA-Zé]\", \" \", letters_only) \n",
    "    \n",
    "# 3. Convert to lower case and split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    \n",
    "# 4. In Python, searching a set is much faster than searching a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "\n",
    "# 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops \n",
    "                            and \"'\" not in w  \n",
    "                            and not w.startswith('@')\n",
    "                            and w != 'rt']   \n",
    "\n",
    "\n",
    "# 6. Join the words back into one string separated by space and return the result.\n",
    "    return( \" \".join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned texet: one see cause one else following pretty awesome\n",
      "Original texet:     You're the only one who can see this cause no one else is following me this is for you because you're pretty awesome\n"
     ]
    }
   ],
   "source": [
    "clean_tweet = clean( train['SentimentText'][22] )\n",
    "print (\"Cleaned texet:\", clean_tweet)\n",
    "print (\"Original texet:\", train['SentimentText'][22] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_tweets = train['SentimentText'].size \n",
    "clean_tweets = []\n",
    "\n",
    "for i in range( 0, num_tweets ):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean reviews\n",
    "    clean_tweets.append(clean( train[\"SentimentText\"][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>cleantweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>sad apl friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>missed new moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>omg already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>omgaga im sooo im gunna cry dentist since supo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>think mi bf cheating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿ItemID  Sentiment SentimentSource  \\\n",
       "0        1          0    Sentiment140   \n",
       "1        2          0    Sentiment140   \n",
       "2        3          1    Sentiment140   \n",
       "3        4          0    Sentiment140   \n",
       "4        5          0    Sentiment140   \n",
       "\n",
       "                                       SentimentText  \\\n",
       "0                       is so sad for my APL frie...   \n",
       "1                     I missed the New Moon trail...   \n",
       "2                            omg its already 7:30 :O   \n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "4           i think mi bf is cheating on me!!!   ...   \n",
       "\n",
       "                                         cleantweets  \n",
       "0                                     sad apl friend  \n",
       "1                            missed new moon trailer  \n",
       "2                                        omg already  \n",
       "3  omgaga im sooo im gunna cry dentist since supo...  \n",
       "4                               think mi bf cheating  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['cleantweets'] = clean_tweets\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv('../Data/train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_mini = train.loc[np.random.choice(train.index, 100000, replace=False)]\n",
    "train_mini.to_csv('../Data.train_mini.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
